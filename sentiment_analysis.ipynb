{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e16e03c-1d4d-4366-98a5-7bcae67c8f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /home/siwalt1/.pyenv/versions/3.13.0/lib/python3.13/site-packages (3.9.1)\n",
      "Requirement already satisfied: click in /home/siwalt1/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in /home/siwalt1/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/siwalt1/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /home/siwalt1/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from nltk) (4.67.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "!pip install better_profanity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49d725d3-96b1-46d8-8e80-85082e538313",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from better_profanity import profanity \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78f10d48-6272-4340-a483-f8a5ff544a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/siwalt1/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download VADER lexicon if not already installed\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Initialize VADER sentiment analyzer\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Optional: Load custom profanity words (if you want to extend the default list)\n",
    "# profanity.load_censor_words_from_file('custom_bad_words.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e805960-d8fc-44df-9cc5-6fed9dd32f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posts DataFrame:\n",
      "  platform       id                                              title  \\\n",
      "0   Reddit  1hukxa5  New California law prohibits using AI as basis...   \n",
      "1   Reddit  1ew0zis  Donald Trump Falsely Claims Taylor Swift Endor...   \n",
      "2   Reddit  1epqzea  Trump falsely claims Harris rally crowd ‘didn’...   \n",
      "3   Reddit  1evuk2a  Trump Falls For AI-Generated Taylor Swift Fans...   \n",
      "4   Reddit  1eb9fyu  AOC’s Deepfake AI Porn Bill Unanimously Passes...   \n",
      "\n",
      "  content     timestamp  comments_count  upvotes          author topic board  \n",
      "0     NaN  1.736120e+09             559  28591.0     AskRedditOG   NaN   NaN  \n",
      "1     NaN  1.724072e+09            1488  22062.0   MiaValeWrites   NaN   NaN  \n",
      "2     NaN  1.723399e+09            1144   8092.0      majorchamp   NaN   NaN  \n",
      "3     NaN  1.724047e+09             496   6332.0  TheMoonMonstar   NaN   NaN  \n",
      "4     NaN  1.721847e+09             400   9090.0    rollingstone   NaN   NaN  \n",
      "\n",
      "Comments DataFrame:\n",
      "  comment_id                                       comment_text  \\\n",
      "0    m5lxp5i  \\nAs a reminder, this subreddit [is for civil ...   \n",
      "1    m5ly4h5  I'm eagerly awaiting the government regulation...   \n",
      "2    m5lzb45                                          [deleted]   \n",
      "3    m5n04gz  Jesus, just regulate the industry already. Tak...   \n",
      "4    m5n7h8d  California fuckin' LEADING THE NATION once aga...   \n",
      "\n",
      "   comment_author  comment_score  comment_timestamp  post_id platform  \n",
      "0   AutoModerator            1.0       1.736120e+09  1hukxa5   Reddit  \n",
      "1   TheParadoxigm         3709.0       1.736121e+09  1hukxa5   Reddit  \n",
      "2       Anonymous         1330.0       1.736121e+09  1hukxa5   Reddit  \n",
      "3  NoCoolNameMatt          533.0       1.736133e+09  1hukxa5   Reddit  \n",
      "4  smugfruitplate           93.0       1.736136e+09  1hukxa5   Reddit  \n"
     ]
    }
   ],
   "source": [
    "# Load posts and comments data\n",
    "posts_df_ai = pd.read_csv('data/ai_posts.csv')\n",
    "comments_df_ai = pd.read_csv('data/ai_comments.csv')\n",
    "posts_df_trump = pd.read_csv('data/trump_posts.csv')\n",
    "comments_df_trump = pd.read_csv('data/trump_comments.csv')\n",
    "posts_df_health = pd.read_csv('data/health_posts.csv')\n",
    "comments_df_health = pd.read_csv('data/health_comments.csv')\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(\"Posts DataFrame:\")\n",
    "print(posts_df_ai.head())\n",
    "print(\"\\nComments DataFrame:\")\n",
    "print(comments_df_ai.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c57dd734-1b87-4c24-abbe-2ff8a9c1415b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get sentiment score https://www.nltk.org/api/nltk.sentiment.vader.html#nltk.sentiment.vader.SentimentIntensityAnalyzer.polarity_scores\n",
    "def get_sentiment(text):\n",
    "    if pd.isna(text):  # Handle missing/empty text\n",
    "        return 0.0\n",
    "    scores = sid.polarity_scores(text) #{'neg': 0.0, 'neu': 0.278, 'pos': 0.722, 'compound': 0.3804}\n",
    "    return scores['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6bd0c2bc-eaca-45f4-a03b-daa8d6a8f773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Post Title Sentiment Summary:\n",
      "count    341.000000\n",
      "mean      -0.065956\n",
      "std        0.341506\n",
      "min       -0.897900\n",
      "25%       -0.296000\n",
      "50%        0.000000\n",
      "75%        0.000000\n",
      "max        0.794400\n",
      "Name: title_sentiment, dtype: float64\n",
      "\n",
      "Comment Sentiment Summary:\n",
      "count    35949.00000\n",
      "mean        -0.04230\n",
      "std          0.49339\n",
      "min         -0.99840\n",
      "25%         -0.44040\n",
      "50%          0.00000\n",
      "75%          0.33820\n",
      "max          0.99980\n",
      "Name: comment_sentiment, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Function to get sentiment score\n",
    "def get_sentiment(text):\n",
    "    if pd.isna(text):  # Handle missing/empty text\n",
    "        return 0.0\n",
    "    scores = sid.polarity_scores(text)\n",
    "    return scores['compound']\n",
    "\n",
    "# Apply sentiment analysis to post titles\n",
    "posts_df_ai['title_sentiment'] = posts_df_ai['title'].apply(get_sentiment)\n",
    "posts_df_trump['title_sentiment'] = posts_df_trump['title'].apply(get_sentiment)\n",
    "posts_df_health['title_sentiment'] = posts_df_health['title'].apply(get_sentiment)\n",
    "\n",
    "# Apply sentiment analysis to comments\n",
    "comments_df_ai['comment_sentiment'] = comments_df_ai['comment_text'].apply(get_sentiment)\n",
    "comments_df_trump['comment_sentiment'] = comments_df_trump['comment_text'].apply(get_sentiment)\n",
    "comments_df_health['comment_sentiment'] = comments_df_health['comment_text'].apply(get_sentiment)\n",
    "\n",
    "# Summary statistics for sentiment\n",
    "print(\"\\nPost Title Sentiment Summary:\")\n",
    "print(posts_df_ai['title_sentiment'].describe())\n",
    "print(\"\\nComment Sentiment Summary:\")\n",
    "print(comments_df_ai['comment_sentiment'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec1f17a1-f561-4bdd-9763-fd0c1c0c9ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== AI Topic ===\n",
      "\n",
      "Reddit Post Title Sentiment:\n",
      "mean   -0.106148\n",
      "std     0.372706\n",
      "Name: title_sentiment, dtype: float64\n",
      "\n",
      "4chan Post Title Sentiment:\n",
      "mean   -0.049279\n",
      "std     0.327060\n",
      "Name: title_sentiment, dtype: float64\n",
      "\n",
      "Reddit Comment Sentiment:\n",
      "mean   -0.014871\n",
      "std     0.489355\n",
      "Name: comment_sentiment, dtype: float64\n",
      "\n",
      "4chan Comment Sentiment:\n",
      "mean   -0.082757\n",
      "std     0.496541\n",
      "Name: comment_sentiment, dtype: float64\n",
      "\n",
      "Reddit Combined Sentiment (Posts + Comments):\n",
      "mean   -0.015295\n",
      "std     0.488910\n",
      "dtype: float64\n",
      "\n",
      "4chan Combined Sentiment (Posts + Comments):\n",
      "mean   -0.082211\n",
      "std     0.494253\n",
      "dtype: float64\n",
      "\n",
      "=== Trump Topic ===\n",
      "\n",
      "Reddit Post Title Sentiment:\n",
      "mean   -0.189919\n",
      "std     0.366082\n",
      "Name: title_sentiment, dtype: float64\n",
      "\n",
      "4chan Post Title Sentiment:\n",
      "mean   -0.055429\n",
      "std     0.366848\n",
      "Name: title_sentiment, dtype: float64\n",
      "\n",
      "Reddit Comment Sentiment:\n",
      "mean   -0.064080\n",
      "std     0.509328\n",
      "Name: comment_sentiment, dtype: float64\n",
      "\n",
      "4chan Comment Sentiment:\n",
      "mean   -0.123118\n",
      "std     0.534463\n",
      "Name: comment_sentiment, dtype: float64\n",
      "\n",
      "Reddit Combined Sentiment (Posts + Comments):\n",
      "mean   -0.064335\n",
      "std     0.509108\n",
      "dtype: float64\n",
      "\n",
      "4chan Combined Sentiment (Posts + Comments):\n",
      "mean   -0.121936\n",
      "std     0.532045\n",
      "dtype: float64\n",
      "\n",
      "=== Health Topic ===\n",
      "\n",
      "Reddit Post Title Sentiment:\n",
      "mean   -0.053558\n",
      "std     0.493428\n",
      "Name: title_sentiment, dtype: float64\n",
      "\n",
      "4chan Post Title Sentiment:\n",
      "mean    0.008294\n",
      "std     0.388344\n",
      "Name: title_sentiment, dtype: float64\n",
      "\n",
      "Reddit Comment Sentiment:\n",
      "mean   -0.020895\n",
      "std     0.512334\n",
      "Name: comment_sentiment, dtype: float64\n",
      "\n",
      "4chan Comment Sentiment:\n",
      "mean   -0.107333\n",
      "std     0.546997\n",
      "Name: comment_sentiment, dtype: float64\n",
      "\n",
      "Reddit Combined Sentiment (Posts + Comments):\n",
      "mean   -0.020975\n",
      "std     0.512285\n",
      "dtype: float64\n",
      "\n",
      "4chan Combined Sentiment (Posts + Comments):\n",
      "mean   -0.104988\n",
      "std     0.544314\n",
      "dtype: float64\n",
      "\n",
      "=== Overall Combined Sentiment Per Topic (Across Platforms) ===\n",
      "\n",
      "AI Topic (All Platforms):\n",
      "mean   -0.042523\n",
      "std     0.492183\n",
      "dtype: float64\n",
      "\n",
      "Trump Topic (All Platforms):\n",
      "mean   -0.071679\n",
      "std     0.512445\n",
      "dtype: float64\n",
      "\n",
      "Health Topic (All Platforms):\n",
      "mean   -0.022652\n",
      "std     0.513072\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Individual sentiment calculations (already provided)\n",
    "reddit_posts_sentiment_ai = posts_df_ai[posts_df_ai['platform'] == 'Reddit']['title_sentiment'].agg(['mean', 'std'])\n",
    "chan_posts_sentiment_ai = posts_df_ai[posts_df_ai['platform'] == '4chan']['title_sentiment'].agg(['mean', 'std'])\n",
    "reddit_comments_sentiment_ai = comments_df_ai[comments_df_ai['platform'] == 'Reddit']['comment_sentiment'].agg(['mean', 'std'])\n",
    "chan_comments_sentiment_ai = comments_df_ai[comments_df_ai['platform'] == '4chan']['comment_sentiment'].agg(['mean', 'std'])\n",
    "\n",
    "reddit_posts_sentiment_trump = posts_df_trump[posts_df_trump['platform'] == 'Reddit']['title_sentiment'].agg(['mean', 'std'])\n",
    "chan_posts_sentiment_trump = posts_df_trump[posts_df_trump['platform'] == '4chan']['title_sentiment'].agg(['mean', 'std'])\n",
    "reddit_comments_sentiment_trump = comments_df_trump[comments_df_trump['platform'] == 'Reddit']['comment_sentiment'].agg(['mean', 'std'])\n",
    "chan_comments_sentiment_trump = comments_df_trump[comments_df_trump['platform'] == '4chan']['comment_sentiment'].agg(['mean', 'std'])\n",
    "\n",
    "reddit_posts_sentiment_health = posts_df_health[posts_df_health['platform'] == 'Reddit']['title_sentiment'].agg(['mean', 'std'])\n",
    "chan_posts_sentiment_health = posts_df_health[posts_df_health['platform'] == '4chan']['title_sentiment'].agg(['mean', 'std'])\n",
    "reddit_comments_sentiment_health = comments_df_health[comments_df_health['platform'] == 'Reddit']['comment_sentiment'].agg(['mean', 'std'])\n",
    "chan_comments_sentiment_health = comments_df_health[comments_df_health['platform'] == '4chan']['comment_sentiment'].agg(['mean', 'std'])\n",
    "\n",
    "# Combined sentiments (posts and comments)\n",
    "combined_sentiment_ai_reddit = pd.concat([posts_df_ai[posts_df_ai['platform'] == 'Reddit']['title_sentiment'], \n",
    "                                         comments_df_ai[comments_df_ai['platform'] == 'Reddit']['comment_sentiment']]).agg(['mean', 'std'])\n",
    "combined_sentiment_ai_4chan = pd.concat([posts_df_ai[posts_df_ai['platform'] == '4chan']['title_sentiment'], \n",
    "                                        comments_df_ai[comments_df_ai['platform'] == '4chan']['comment_sentiment']]).agg(['mean', 'std'])\n",
    "\n",
    "combined_sentiment_trump_reddit = pd.concat([posts_df_trump[posts_df_trump['platform'] == 'Reddit']['title_sentiment'], \n",
    "                                            comments_df_trump[comments_df_trump['platform'] == 'Reddit']['comment_sentiment']]).agg(['mean', 'std'])\n",
    "combined_sentiment_trump_4chan = pd.concat([posts_df_trump[posts_df_trump['platform'] == '4chan']['title_sentiment'], \n",
    "                                           comments_df_trump[comments_df_trump['platform'] == '4chan']['comment_sentiment']]).agg(['mean', 'std'])\n",
    "\n",
    "combined_sentiment_health_reddit = pd.concat([posts_df_health[posts_df_health['platform'] == 'Reddit']['title_sentiment'], \n",
    "                                             comments_df_health[comments_df_health['platform'] == 'Reddit']['comment_sentiment']]).agg(['mean', 'std'])\n",
    "combined_sentiment_health_4chan = pd.concat([posts_df_health[posts_df_health['platform'] == '4chan']['title_sentiment'], \n",
    "                                            comments_df_health[comments_df_health['platform'] == '4chan']['comment_sentiment']]).agg(['mean', 'std'])\n",
    "\n",
    "# Printing per topic\n",
    "print(\"=== AI Topic ===\")\n",
    "print(\"\\nReddit Post Title Sentiment:\")\n",
    "print(reddit_posts_sentiment_ai)\n",
    "print(\"\\n4chan Post Title Sentiment:\")\n",
    "print(chan_posts_sentiment_ai)\n",
    "print(\"\\nReddit Comment Sentiment:\")\n",
    "print(reddit_comments_sentiment_ai)\n",
    "print(\"\\n4chan Comment Sentiment:\")\n",
    "print(chan_comments_sentiment_ai)\n",
    "print(\"\\nReddit Combined Sentiment (Posts + Comments):\")\n",
    "print(combined_sentiment_ai_reddit)\n",
    "print(\"\\n4chan Combined Sentiment (Posts + Comments):\")\n",
    "print(combined_sentiment_ai_4chan)\n",
    "\n",
    "print(\"\\n=== Trump Topic ===\")\n",
    "print(\"\\nReddit Post Title Sentiment:\")\n",
    "print(reddit_posts_sentiment_trump)\n",
    "print(\"\\n4chan Post Title Sentiment:\")\n",
    "print(chan_posts_sentiment_trump)\n",
    "print(\"\\nReddit Comment Sentiment:\")\n",
    "print(reddit_comments_sentiment_trump)\n",
    "print(\"\\n4chan Comment Sentiment:\")\n",
    "print(chan_comments_sentiment_trump)\n",
    "print(\"\\nReddit Combined Sentiment (Posts + Comments):\")\n",
    "print(combined_sentiment_trump_reddit)\n",
    "print(\"\\n4chan Combined Sentiment (Posts + Comments):\")\n",
    "print(combined_sentiment_trump_4chan)\n",
    "\n",
    "print(\"\\n=== Health Topic ===\")\n",
    "print(\"\\nReddit Post Title Sentiment:\")\n",
    "print(reddit_posts_sentiment_health)\n",
    "print(\"\\n4chan Post Title Sentiment:\")\n",
    "print(chan_posts_sentiment_health)\n",
    "print(\"\\nReddit Comment Sentiment:\")\n",
    "print(reddit_comments_sentiment_health)\n",
    "print(\"\\n4chan Comment Sentiment:\")\n",
    "print(chan_comments_sentiment_health)\n",
    "print(\"\\nReddit Combined Sentiment (Posts + Comments):\")\n",
    "print(combined_sentiment_health_reddit)\n",
    "print(\"\\n4chan Combined Sentiment (Posts + Comments):\")\n",
    "print(combined_sentiment_health_4chan)\n",
    "\n",
    "# Overall combined sentiment per topic (across platforms)\n",
    "combined_sentiment_ai_all = pd.concat([posts_df_ai['title_sentiment'], comments_df_ai['comment_sentiment']]).agg(['mean', 'std'])\n",
    "combined_sentiment_trump_all = pd.concat([posts_df_trump['title_sentiment'], comments_df_trump['comment_sentiment']]).agg(['mean', 'std'])\n",
    "combined_sentiment_health_all = pd.concat([posts_df_health['title_sentiment'], comments_df_health['comment_sentiment']]).agg(['mean', 'std'])\n",
    "\n",
    "print(\"\\n=== Overall Combined Sentiment Per Topic (Across Platforms) ===\")\n",
    "print(\"\\nAI Topic (All Platforms):\")\n",
    "print(combined_sentiment_ai_all)\n",
    "print(\"\\nTrump Topic (All Platforms):\")\n",
    "print(combined_sentiment_trump_all)\n",
    "print(\"\\nHealth Topic (All Platforms):\")\n",
    "print(combined_sentiment_health_all)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-3.13",
   "language": "python",
   "name": "python-3.13"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
